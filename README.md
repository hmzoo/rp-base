# RunPod Serverless - Projet d'apprentissage

Ce projet est un template de base pour apprendre Ã  crÃ©er et dÃ©ployer des fonctions serverless sur RunPod.

## ğŸ“‹ Structure du projet

```
rp-base/
â”œâ”€â”€ handler.py           # Handler principal pour la fonction serverless
â”œâ”€â”€ test_local.py        # Tests locaux du handler
â”œâ”€â”€ test_api.py          # Exemples d'utilisation de l'API RunPod
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ Dockerfile          # Configuration Docker pour le dÃ©ploiement
â””â”€â”€ README.md           # Ce fichier
```

## ğŸš€ DÃ©marrage rapide

### 1. Installation des dÃ©pendances locales

```bash
# CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
source venv/bin/activate  # Sur Linux/Mac
# ou
venv\Scripts\activate  # Sur Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 2. Tester localement

```bash
# ExÃ©cuter les tests locaux
python test_local.py
```

### 3. Construire l'image Docker

```bash
# Construire l'image
docker build -t runpod-serverless-base .

# Tester l'image localement (optionnel)
docker run --rm runpod-serverless-base
```

### 4. DÃ©ployer sur RunPod

1. CrÃ©ez un compte sur [RunPod](https://www.runpod.io/)
2. Poussez votre image Docker sur Docker Hub ou un autre registre:
   ```bash
   docker tag runpod-serverless-base votre-username/runpod-serverless-base
   docker push votre-username/runpod-serverless-base
   ```
3. Dans le dashboard RunPod:
   - Allez dans "Serverless" > "New Endpoint"
   - Entrez l'URL de votre image Docker
   - Configurez les ressources (GPU/CPU)
   - DÃ©ployez!

## ğŸ“š Concepts clÃ©s

### Le Handler

Le handler est la fonction principale qui traite les requÃªtes. Il reÃ§oit un Ã©vÃ©nement avec un `input` et retourne un rÃ©sultat:

```python
def handler(event):
    job_input = event.get('input', {})
    # Votre logique ici
    return {'output': 'rÃ©sultat'}
```

### Types de handlers

1. **Handler simple**: Traite une requÃªte et retourne un rÃ©sultat
2. **Handler avec streaming**: Utilise un gÃ©nÃ©rateur pour retourner des rÃ©sultats progressifs

### Format d'entrÃ©e

```json
{
  "input": {
    "message": "Votre message",
    "operation": "echo|uppercase|reverse|length"
  }
}
```

### Format de sortie

```json
{
  "output": "RÃ©sultat de l'opÃ©ration",
  "operation": "echo"
}
```

## ğŸ”§ Personnalisation

### Ajouter vos propres opÃ©rations

Modifiez [handler.py](handler.py) pour ajouter vos propres opÃ©rations:

```python
elif operation == 'ma_nouvelle_operation':
    result = {
        'output': votre_traitement(message),
        'operation': operation
    }
```

### Ajouter des dÃ©pendances

Ajoutez vos dÃ©pendances dans [requirements.txt](requirements.txt):

```txt
torch>=2.0.0
transformers>=4.30.0
```

### Utiliser un GPU

Si votre fonction nÃ©cessite un GPU (par exemple pour du ML/AI):

1. Modifiez le Dockerfile pour utiliser une image CUDA:
   ```dockerfile
   FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04
   ```
2. Installez PyTorch ou TensorFlow selon vos besoins
3. SÃ©lectionnez un GPU dans les paramÃ¨tres de l'endpoint RunPod

## ğŸ§ª Tests

### Tests locaux

```bash
python test_local.py
```

### Tests API (aprÃ¨s dÃ©ploiement)

1. Obtenez votre clÃ© API depuis le dashboard RunPod
2. DÃ©finissez la variable d'environnement:
   ```bash
   export RUNPOD_API_KEY="votre-clÃ©-api"
   ```
3. Modifiez [test_api.py](test_api.py) avec votre endpoint ID
4. ExÃ©cutez:
   ```bash
   python test_api.py
   ```

## ğŸ“– Ressources

- [Documentation RunPod](https://docs.runpod.io/)
- [RunPod Python SDK](https://github.com/runpod/runpod-python)
- [Exemples de serverless RunPod](https://github.com/runpod-workers)

## ğŸ¯ Prochaines Ã©tapes

1. âœ… Comprendre le fonctionnement de base du handler
2. âœ… Tester localement vos modifications
3. ğŸ”„ Ajouter votre propre logique mÃ©tier
4. ğŸ”„ DÃ©ployer sur RunPod
5. ğŸ”„ Tester avec l'API RunPod
6. ğŸ”„ Optimiser les performances et les coÃ»ts

## ğŸ’¡ Conseils

- **Gardez vos images Docker lÃ©gÃ¨res** pour des dÃ©ploiements rapides
- **Testez toujours localement** avant de dÃ©ployer
- **Utilisez des variables d'environnement** pour les secrets
- **GÃ©rez les erreurs gracieusement** dans votre handler
- **Documentez votre API** pour faciliter l'utilisation

## ğŸ“ License

Ce projet est un template d'apprentissage et peut Ãªtre utilisÃ© librement.