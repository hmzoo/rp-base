"""
RunPod Serverless - Talking Head API with Coqui TTS
===================================================
G√©n√®re une vid√©o o√π une personne sur une image "lit" un texte.
Utilise Coqui TTS XTTS_v2 pour une qualit√© audio professionnelle.

Input:
    - image: URL ou base64 de l'image de la personne
    - text: Le texte √† faire lire
    - voice: (optionnel) Nom du speaker ou fichier audio pour clonage
    - language: (optionnel) Langue du texte (default: 'fr')

Output:
    - audio_base64: Audio encod√© en base64
    - audio_size_bytes: Taille de l'audio
"""

import runpod
import base64
import os
import tempfile
import requests
from pathlib import Path
import json
import torch

# Initialisation globale du mod√®le TTS (charg√© une seule fois)
TTS_MODEL = None

def init_tts_model():
    """Initialise le mod√®le Coqui TTS XTTS_v2"""
    global TTS_MODEL
    
    if TTS_MODEL is None:
        print("üîÑ Chargement du mod√®le Coqui TTS XTTS_v2...")
        from TTS.api import TTS
        
        # V√©rifier si GPU disponible
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"   Device: {device}")
        
        # Charger le mod√®le multilingue XTTS_v2
        TTS_MODEL = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
        print("   ‚úì Mod√®le charg√©")
    
    return TTS_MODEL


def download_image(image_input):
    """
    T√©l√©charge ou d√©code l'image d'entr√©e.
    
    Args:
        image_input: URL ou base64 de l'image
    
    Returns:
        str: Chemin vers le fichier image temporaire
    """
    temp_dir = tempfile.mkdtemp()
    image_path = os.path.join(temp_dir, "input_image.jpg")
    
    if image_input.startswith('http://') or image_input.startswith('https://'):
        # T√©l√©charger depuis URL
        response = requests.get(image_input)
        response.raise_for_status()
        with open(image_path, 'wb') as f:
            f.write(response.content)
    elif image_input.startswith('data:image'):
        # D√©coder base64
        header, encoded = image_input.split(',', 1)
        image_data = base64.b64decode(encoded)
        with open(image_path, 'wb') as f:
            f.write(image_data)
    else:
        # Assumer que c'est du base64 sans header
        image_data = base64.b64decode(image_input)
        with open(image_path, 'wb') as f:
            f.write(image_data)
    
    return image_path, temp_dir


def text_to_speech(text, language='fr', voice='Claribel Dervla'):
    """
    Convertit le texte en audio avec Coqui TTS XTTS_v2.
    
    Speakers disponibles par d√©faut:
    - Claribel Dervla (f√©minin, clair)
    - Daisy Studious (f√©minin, pos√©)
    - Gracie Wise (f√©minin, mature)
    - Tammie Ema (f√©minin, jeune)
    - Alison Dietlinde (f√©minin, professionnel)
    - Ana Florence (f√©minin, chaleureux)
    - Annmarie Nele (f√©minin, √©nergique)
    - Asya Anara (f√©minin, doux)
    - Brenda Stern (f√©minin, autoritaire)
    - Gitta Nikolina (f√©minin, amical)
    - Henriette Usha (f√©minin, calme)
    - Sofia Hellen (f√©minin, √©l√©gant)
    - Tammy Grit (f√©minin, dynamique)
    - Tanja Adelina (f√©minin, confiant)
    - Vjollca Johnnie (f√©minin, expressif)
    - Andrew Chipper (masculin, jeune)
    - Badr Odhiambo (masculin, grave)
    - Dionisio Schuyler (masculin, mature)
    - Royston Min (masculin, calme)
    - Viktor Eka (masculin, autoritaire)
    - Abrahan Mack (masculin, chaleureux)
    - Adde Michal (masculin, amical)
    - Baldur Sanjin (masculin, puissant)
    - Craig Gutsy (masculin, √©nergique)
    - Damien Black (masculin, s√©rieux)
    - Gilberto Mathias (masculin, professionnel)
    - Ilkin Urbano (masculin, confiant)
    - Kazuhiko Atallah (masculin, pos√©)
    - Ludvig Milivoj (masculin, doux)
    - Suad Qasim (masculin, expressif)
    
    Clonage de voix:
    - Passez l'URL ou le chemin d'un fichier audio de 3-10 secondes
    
    Args:
        text: Le texte √† synth√©tiser
        language: Code langue (fr, en, es, de, it, pt, pl, tr, ru, nl, cs, ar, zh-cn, ja, hu, ko, hi)
        voice: Nom du speaker ou URL/chemin audio pour clonage
    
    Returns:
        tuple: (audio_path, temp_dir)
    """
    temp_dir = tempfile.mkdtemp()
    audio_path = os.path.join(temp_dir, "speech.wav")
    
    # Initialiser le mod√®le
    tts = init_tts_model()
    
    print(f"   üé§ Synth√®se Coqui TTS: langue={language}, speaker={voice}")
    
    try:
        # V√©rifier si c'est un clonage de voix (URL ou fichier)
        if voice.startswith('http://') or voice.startswith('https://') or os.path.isfile(voice):
            print(f"   üé≠ Clonage de voix depuis: {voice}")
            # T√©l√©charger l'audio de r√©f√©rence si c'est une URL
            if voice.startswith('http'):
                ref_audio = os.path.join(temp_dir, "reference_voice.wav")
                response = requests.get(voice)
                with open(ref_audio, 'wb') as f:
                    f.write(response.content)
                voice = ref_audio
            
            # G√©n√©rer avec clonage
            tts.tts_to_file(
                text=text,
                speaker_wav=voice,
                language=language,
                file_path=audio_path
            )
        else:
            # Utiliser un speaker par d√©faut
            tts.tts_to_file(
                text=text,
                speaker=voice,
                language=language,
                file_path=audio_path
            )
        
        print(f"   ‚úì Audio g√©n√©r√©: {audio_path}")
        return audio_path, temp_dir
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Erreur TTS: {e}")
        # Fallback sur un speaker par d√©faut
        print(f"   üîÑ Tentative avec speaker par d√©faut...")
        tts.tts_to_file(
            text=text,
            speaker="Claribel Dervla",
            language=language,
            file_path=audio_path
        )
        return audio_path, temp_dir


def generate_talking_head(image_path, audio_path, output_path):
    """
    G√©n√®re la vid√©o talking head.
    
    Pour une impl√©mentation compl√®te, utilisez:
    - Wav2Lip: https://github.com/Rudrabha/Wav2Lip
    - SadTalker: https://github.com/OpenTalker/SadTalker
    - D-ID API (commercial)
    
    Args:
        image_path: Chemin vers l'image
        audio_path: Chemin vers l'audio
        output_path: Chemin de sortie pour la vid√©o
    
    Returns:
        str: Chemin vers la vid√©o g√©n√©r√©e
    """
    
    # TODO: Impl√©menter avec Wav2Lip ou SadTalker
    raise NotImplementedError(
        "Impl√©mentation de Wav2Lip/SadTalker requise. "
        "Voir les instructions dans le README_TALKING_HEAD.md"
    )


def upload_to_storage(video_path):
    """
    Upload la vid√©o vers un stockage (S3, etc.).
    
    Args:
        video_path: Chemin local de la vid√©o
    
    Returns:
        str: URL publique de la vid√©o
    """
    # TODO: Impl√©menter l'upload vers S3 ou autre
    return f"file://{video_path}"


def handler(event):
    """
    Handler principal pour l'API Talking Head avec Coqui TTS.
    
    Args:
        event: √âv√©nement RunPod contenant:
            - input.image: URL ou base64 de l'image
            - input.text: Texte √† faire lire
            - input.voice: (optionnel) Speaker ou URL audio pour clonage (default: 'Claribel Dervla')
            - input.language: (optionnel) Langue (default: 'fr')
    
    Returns:
        dict: R√©sultat avec audio_base64 et m√©tadonn√©es
    """
    try:
        job_input = event.get('input', {})
        
        # Validation des entr√©es
        if 'image' not in job_input:
            return {'error': 'Le champ "image" est requis (URL ou base64)'}
        
        if 'text' not in job_input:
            return {'error': 'Le champ "text" est requis'}
        
        image_input = job_input['image']
        text = job_input['text']
        language = job_input.get('language', 'fr')
        voice = job_input.get('voice', 'Claribel Dervla')
        
        print(f"üì• Traitement: texte='{text[:50]}...', langue={language}, voix={voice}")
        
        # √âtape 1: T√©l√©charger/d√©coder l'image
        print("1Ô∏è‚É£ T√©l√©chargement de l'image...")
        image_path, image_temp_dir = download_image(image_input)
        print(f"   ‚úì Image sauvegard√©e: {image_path}")
        
        # √âtape 2: G√©n√©rer l'audio (TTS)
        print("2Ô∏è‚É£ G√©n√©ration de l'audio (Coqui TTS XTTS_v2)...")
        audio_path, audio_temp_dir = text_to_speech(text, language, voice)
        
        # Encoder l'audio en base64 pour le retour
        with open(audio_path, 'rb') as audio_file:
            audio_base64 = base64.b64encode(audio_file.read()).decode('utf-8')
            audio_size = os.path.getsize(audio_path)
        
        print(f"   ‚úì Audio encod√©: {audio_size} bytes")
        
        # √âtape 3: G√©n√©rer la vid√©o talking head
        print("3Ô∏è‚É£ G√©n√©ration de la vid√©o talking head...")
        output_dir = tempfile.mkdtemp()
        output_path = os.path.join(output_dir, "output_video.mp4")
        
        try:
            generate_talking_head(image_path, audio_path, output_path)
            print(f"   ‚úì Vid√©o g√©n√©r√©e: {output_path}")
        except NotImplementedError as e:
            # Nettoyage
            import shutil
            shutil.rmtree(image_temp_dir, ignore_errors=True)
            shutil.rmtree(audio_temp_dir, ignore_errors=True)
            shutil.rmtree(output_dir, ignore_errors=True)
            
            return {
                'error': 'Mod√®le talking head non configur√©',
                'message': str(e),
                'todo': 'Impl√©menter Wav2Lip ou SadTalker (voir README)',
                'status': 'partial_success',
                'audio_generated': True,
                'audio_base64': audio_base64,
                'audio_size_bytes': audio_size,
                'image_processed': True,
                'tts_engine': 'Coqui TTS XTTS_v2',
                'speaker': voice
            }
        
        # √âtape 4: Upload de la vid√©o
        print("4Ô∏è‚É£ Upload de la vid√©o...")
        video_url = upload_to_storage(output_path)
        print(f"   ‚úì Vid√©o disponible: {video_url}")
        
        # Nettoyage
        import shutil
        shutil.rmtree(image_temp_dir, ignore_errors=True)
        shutil.rmtree(audio_temp_dir, ignore_errors=True)
        shutil.rmtree(output_dir, ignore_errors=True)
        
        # R√©sultat
        return {
            'status': 'success',
            'video_url': video_url,
            'text': text,
            'language': language,
            'speaker': voice,
            'duration': None,
            'message': 'Vid√©o g√©n√©r√©e avec succ√®s',
            'tts_engine': 'Coqui TTS XTTS_v2'
        }
        
    except Exception as e:
        import traceback
        return {
            'error': str(e),
            'type': type(e).__name__,
            'traceback': traceback.format_exc()
        }


if __name__ == "__main__":
    # Mode d√©veloppement: test local
    print("üöÄ D√©marrage du worker RunPod - Talking Head API (Coqui TTS)")
    print("=" * 60)
    
    # D√©marrer le worker
    runpod.serverless.start({"handler": handler})
